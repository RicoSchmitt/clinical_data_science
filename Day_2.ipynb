{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TxxL9UEaqO9"
      },
      "source": [
        "# **Clinical Data Science and Machine Learning with Python**\n",
        "\n",
        "## **Day 2**\n",
        "\n",
        "**Instructor**: Teresa Krieger, BIH/CharitÃ© (teresa.krieger@charite.de)\n",
        "\n",
        "**Content**:\n",
        "\n",
        "1.   References\n",
        "2.   Library imports and data download\n",
        "3.   Data preparation\n",
        "4.   Model building\n",
        "5.   Model training\n",
        "6.   Model evaluation\n",
        "7.   Model prediction\n",
        "8.   Optional: More MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB4ROcAPaqPB"
      },
      "source": [
        "---\n",
        "## **1. References**\n",
        "\n",
        "In this course, we will use Python 3.6 (default in Colab as of February 2021).\n",
        "The following documentation and links might be useful to you:\n",
        "\n",
        "- Deep Learning:\n",
        "  - https://www.deeplearningbook.org/\n",
        "- Tensorflow and Keras:\n",
        "  - https://www.tensorflow.org/tutorials/\n",
        "  - https://keras.io/guides/\n",
        "- Source of the pneumonia X-ray dataset:\n",
        "  - https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\n",
        "- We will loosely follow these tutorials:\n",
        "  - https://www.kaggle.com/code/amyjang/tensorflow-pneumonia-classification-on-x-rays/notebook\n",
        "\n",
        "You can also take a look at [this](https://www.youtube.com/playlist?list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF) machine learning series on Youtube, where you can learn more about e.g. bias and variance, regression, and other common machine learning algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5Seipdq1Owq"
      },
      "source": [
        "---\n",
        "## **2. Library imports and data download**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.24.3\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "print(np.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: protobuf\n",
            "Version: 4.25.2\n",
            "Summary: \n",
            "Home-page: https://developers.google.com/protocol-buffers/\n",
            "Author: protobuf@googlegroups.com\n",
            "Author-email: protobuf@googlegroups.com\n",
            "License: 3-Clause BSD License\n",
            "Location: /Users/ricoandreschmitt/anaconda3/envs/myenv/lib/python3.8/site-packages\n",
            "Requires: \n",
            "Required-by: tensorboard, tensorflow\n"
          ]
        }
      ],
      "source": [
        "!pip show protobuf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WzGW_2hDCS1e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-11 15:05:56.879389: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "bases must be types",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpimg\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.8/site-packages/tensorflow/__init__.py:38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.8/site-packages/tensorflow/python/__init__.py:37\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# go/tf-wildcard-import\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n",
            "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.8/site-packages/tensorflow/python/eager/context.py:29\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mabsl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_pb2\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rewriter_config_pb2\n",
            "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.8/site-packages/tensorflow/core/framework/function_pb2.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Generated by the protocol buffer compiler.  DO NOT EDIT!\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# source: tensorflow/core/framework/function.proto\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"Generated protocol buffer code.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n",
            "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.8/site-packages/google/protobuf/internal/builder.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m __author__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjieluo@google.com (Jie Luo)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m enum_type_wrapper\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m python_message\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m message \u001b[38;5;28;01mas\u001b[39;00m _message\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reflection \u001b[38;5;28;01mas\u001b[39;00m _reflection\n",
            "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.8/site-packages/google/protobuf/internal/python_message.py:36\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mweakref\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m descriptor_mod\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m message \u001b[38;5;28;01mas\u001b[39;00m message_mod\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m text_format\n",
            "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.8/site-packages/google/protobuf/descriptor.py:17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api_implementation\n\u001b[1;32m     19\u001b[0m _USE_C_DESCRIPTORS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_implementation\u001b[38;5;241m.\u001b[39mType() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     21\u001b[0m   \u001b[38;5;66;03m# Used by MakeDescriptor in cpp mode\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py:81\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _implementation_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpp\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     79\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _message\n\u001b[1;32m     82\u001b[0m     sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoogle3.net.proto2.python.internal.cpp._message\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m _message\n\u001b[1;32m     83\u001b[0m     _c_module \u001b[38;5;241m=\u001b[39m _message\n",
            "\u001b[0;31mTypeError\u001b[0m: bases must be types"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras.utils as image\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from google.colab import files\n",
        "\n",
        "import zipfile\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN9ygNZMx-W-"
      },
      "source": [
        "In this session, we will be working with chest X-ray images from patients with and without pneumonia. This data is available on Kaggle. Before we can download it, we need to set up a connection to Kaggle in our colab environment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b8xdW9Jz7ST"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "!wget -O kaggle.json https://www.dropbox.com/s/ewjoj1ge5u130m9/kaggle.json?dl=0\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3dhn08u0_5X"
      },
      "source": [
        "Now we can download the data from Kaggle:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQvWxd7kyAvS"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download paultimothymooney/chest-xray-pneumonia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nnj3SfF1HSl"
      },
      "source": [
        "The dataset is organised into 3 folders (train, test, val) and contains subfolders for each image category (PNEUMONIA/NORMAL). There are 5,863 X-Ray images (JPEG) across the two categories. We still need to unzip the compressed data and store the folder names:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pQ8h2_DyQY1"
      },
      "outputs": [],
      "source": [
        "# Extract compressed data\n",
        "with zipfile.ZipFile('chest-xray-pneumonia.zip', mode='r') as zf:   # Here, mode = 'r' means we are reading the zip file\n",
        "  zf.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaXHfIvT3_Ku"
      },
      "outputs": [],
      "source": [
        "# Define the folder paths:\n",
        "img_dir = os.path.join(os.getcwd(), 'chest_xray')   # This is the parent directory\n",
        "train_img_dir = os.path.join(img_dir, 'train')\n",
        "test_img_dir = os.path.join(img_dir, 'test')\n",
        "val_img_dir = os.path.join(img_dir, 'val')\n",
        "\n",
        "# Print the paths\n",
        "print('Parent directory for images: '+img_dir)\n",
        "print('Directory for training images: '+train_img_dir)\n",
        "print('Directory for test images: '+test_img_dir)\n",
        "print('Directory for validation images: '+val_img_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0sSm0skRS-E"
      },
      "source": [
        "We would now like to take a look at some example images from the NORMAL and PNEUMONIA categories inside our training data folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlLVZN2QRttS"
      },
      "outputs": [],
      "source": [
        "samples_normal=os.listdir(train_img_dir+\"/NORMAL/\")[0:4]\n",
        "samples_pneumonia=os.listdir(train_img_dir+\"/PNEUMONIA/\")[0:4]\n",
        "f, ax = plt.subplots(2,4, figsize=(30,10))\n",
        "for i in range(4):\n",
        "    img = plt.imread(train_img_dir+\"/NORMAL/\"+samples_normal[i])\n",
        "    ax[0,i].imshow(img, cmap='gray')\n",
        "    ax[0,i].set_title(\"Normal\")\n",
        "for i in range(4):\n",
        "    img = plt.imread(train_img_dir+\"/PNEUMONIA/\"+samples_pneumonia[i])\n",
        "    ax[1,i].imshow(img, cmap='gray')\n",
        "    ax[1,i].set_title(\"Pneumonia\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70hnAlK1RT7i"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "local_zip = 'Xrayimage/XrayArchive.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/Xrayimage')\n",
        "zip_ref.close()\n",
        "base_dir = '/XrayImage/chest_xray'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'test')\n",
        "# Create directorys to store the normal and sick lungs\n",
        "train_healthy_dir = os.path.join(train_dir, 'NORMAL')\n",
        "train_sick_dir = os.path.join(train_dir, 'PNEUMONIA')\n",
        "# We use these as validation i.e we don't train with these.\n",
        "validation_healthy_dir = os.path.join(validation_dir, 'NORMAL')\n",
        "validation_sick_dir = os.path.join(validation_dir, 'PNEUMONIA')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn7MGAvG47JO"
      },
      "source": [
        "---\n",
        "## **3. Data preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kxcFyD649mJ"
      },
      "source": [
        "To prepare the images for processing, we will use the `ImageDataGenerator` function from `Keras`. This function automatically generates batches of image data for training and testing our model. Moreover, it can perform real-time data augmentation, for example by introducing random rotations and vertical or horizontal flips. You can find out more in the documentation [here](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator).\n",
        "\n",
        "For now, we will only apply the `rescale` argument to transform all images to a [0...1] grayscale range instead of [0...255] as is common for RGB images. The generator essentially reads images from the source folders in batches when they are required during training and evaluation. We will therefore set up separate instances for training, validation and testing:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBJYfeDo4qoM"
      },
      "outputs": [],
      "source": [
        "train_generator = ImageDataGenerator(rescale = 1/255).flow_from_directory(\n",
        "    'chest_xray/train/',\n",
        "    target_size = (300,300),   # dimensions to which all images will be resized (in pixels)\n",
        "    batch_size = 128,          # data is loaded in batches\n",
        "    class_mode = 'binary'      # refers to the binary labels (0/1)\n",
        ")\n",
        "\n",
        "test_generator = ImageDataGenerator(rescale = 1/255).flow_from_directory(\n",
        "    'chest_xray/test/',\n",
        "    target_size = (300, 300),\n",
        "    batch_size = 128,\n",
        "    class_mode = 'binary'\n",
        ")\n",
        "\n",
        "val_generator = ImageDataGenerator(rescale = 1/255).flow_from_directory(\n",
        "    'chest_xray/val/',\n",
        "    target_size = (300, 300),\n",
        "    batch_size = 128,\n",
        "    class_mode = 'binary'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBQF0ovWU5bP"
      },
      "source": [
        "---\n",
        "## **4. Model building**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKCKbFEYrFTx"
      },
      "source": [
        "The model we are going to build consists of several components:\n",
        "\n",
        "*   **tf.keras.layers.Conv2D()**: the convolution layer which abstracts images features\n",
        "*   **tf.keras.layers.MaxPooling2D()**: a layer to reduce the information in an image while maintaining features\n",
        "*   **tf.keras.layers.Flatten()**: flattens the result into a one-dimensional array\n",
        "*   **tf.keras.layers.Dense()**: a densely connected layer\n",
        "\n",
        "We will build a four-layer convolutional neural network in which each layer consists of a Conv2D() and a MaxPooling2D() step. Then, the output of the final convolutional layer will be flattened and fit to fully connected neurons. A dropout layer is added to avoid overfitting.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_6ikMm5sflP"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "\n",
        "    # Note the input shape is the size of the image (300 x 300 px) x 3 colours\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    # Flatten output\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Densely connected hidden layer with 512 neurons\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "\n",
        "    # Dropout layer\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "    # One output neuron with a sigmoid activation function -\n",
        "    # this will contain a value from 0 ('normal') to 1 ('pneumonia')\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmAGCFx-3E8b"
      },
      "source": [
        "We can inspect the architecture of our model by printing a summary as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22Fgvk9CshP4"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOOvybvXg3zT"
      },
      "outputs": [],
      "source": [
        "keras.utils.plot_model(\n",
        "    model,\n",
        "    to_file=\"model.png\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4Hrrnrsqv3A"
      },
      "source": [
        "Additionally, before the model is fitted for training, it is necessary to configure the specifications as follows:\n",
        "\n",
        "*   **loss**: with a sigmoid activation function in the final step, we select `binary_crossentropy` as the loss function\n",
        "*   **optimizer**: `RMSprop` (Root Mean Square Propagation) with a learning rate of 0.001 will be used\n",
        "*   **metrics**: we will use `accuracy` as our metric to evaluate the prediction accuracy on every epoch\n",
        "\n",
        "We can now compile the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vIpy4YR2rZ0"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(learning_rate=0.001),\n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhRg0cq656Oa"
      },
      "source": [
        "---\n",
        "#### **_Your turn_: Exercises**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxyVGtx06FHz"
      },
      "source": [
        "**Exercise 1**: Define a different sequential model for our images (e.g. using a different number of convolutions and adding one or two more dropout layers). Store this as variable `model2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WivA8_f455hq"
      },
      "outputs": [],
      "source": [
        "model2 = tf.keras.models.Sequential([\n",
        "\n",
        "    # Note the input shape is the size of the image (300 x 300 px) x 3 colours\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(20, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(30, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(60, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(120, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    # Flatten output\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Densely connected hidden layer with 512 neurons\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "\n",
        "    # Dropout layer\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "    # One output neuron with a sigmoid activation function -\n",
        "    # this will contain a value from 0 ('normal') to 1 ('pneumonia')\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFa3FDfS8zg8"
      },
      "source": [
        "---\n",
        "## **5. Model training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhrsxPiF7aiY"
      },
      "source": [
        "Now we are ready to train our model. We will train for 25 epochs and store our progress in `history`. Note that this might take a few minutes - time for some tea or coffee!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApgFjCYT7OG5"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data = val_generator,\n",
        "    epochs = 25\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKnRRz53tC9t"
      },
      "source": [
        "The `history` object contains the `history.history` attribute, which is a record of training loss values and metrics values at successive epochs - this is what we're interested in here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9XQO2zSs_TD"
      },
      "outputs": [],
      "source": [
        "history = history.history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9xEaiCvk5EP"
      },
      "source": [
        "After training, we can save our model and the training history:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6DN8Qxvk9XU"
      },
      "outputs": [],
      "source": [
        "# Save model\n",
        "tf.keras.saving.save_model(\n",
        "    model, 'trained_model.h5', overwrite=True, save_format='h5'\n",
        ")\n",
        "\n",
        "# Save training history\n",
        "with open('training_history', 'wb') as file_pi:\n",
        "  pickle.dump(history, file_pi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gU1-aRZaAXnH"
      },
      "source": [
        "**Taking too long?** If you've finished your tea or coffee but the above is still not done, you can also interrupt execution of the cell by clicking on `Runtime > Interrupt execution` in the top menu. Now you can just download the trained model as well as the training history by executing the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sU8GImBSpuBT"
      },
      "outputs": [],
      "source": [
        "# Load model and training history\n",
        "!wget -O trained_model.h5 https://www.dropbox.com/scl/fi/syngj8c2lijfoo228zl0n/trained_model.h5?rlkey=ec2h2ejk976j065s5rqg5kdvm&dl=0\n",
        "model = tf.keras.saving.load_model('trained_model.h5')\n",
        "\n",
        "!wget -O training_history.pickle https://www.dropbox.com/scl/fi/wxdtgif7kcrgrh08d94ph/training_history?rlkey=yhw2muwjvwzpr71146ks0dxxm&dl=0\n",
        "file_to_read = open('training_history.pickle', 'rb')\n",
        "history = pickle.load(file_to_read)\n",
        "file_to_read.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHzSGLGeqU7_"
      },
      "source": [
        "---\n",
        "## **6. Model evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHiW6pFo_9We"
      },
      "source": [
        "To evaluate our model, we can plot the accuracy as a function of training epochs for our training and validation data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7H4BzqO_X_R"
      },
      "outputs": [],
      "source": [
        "plt.plot(history['accuracy'])\n",
        "plt.plot(history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTMc5JGOOutp"
      },
      "source": [
        "---\n",
        "#### **_Your turn_: Exercises**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_t86ELtOutr"
      },
      "source": [
        "**Exercise 1**: Plot the loss instead of the accuracy for training and validation data. Place the legend in the upper right corner of the plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krNRYiRwOuts"
      },
      "outputs": [],
      "source": [
        "plt.plot(history['loss'])          \n",
        "plt.plot(history['val_loss'])      \n",
        "plt.title('Model Loss')            \n",
        "plt.ylabel('Loss')                 \n",
        "plt.xlabel('Epoch')                \n",
        "plt.legend(['Train', 'Val'], loc='upper right')  \n",
        "plt.show()                        \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9Kn0axUEAJI"
      },
      "source": [
        "---\n",
        "## **7. Model prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrM3Cu6OFsDf"
      },
      "source": [
        "So how does our model perform on unseen data? We can use the `model.evaluate` function to check this.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Q8qexSGFrvl"
      },
      "outputs": [],
      "source": [
        "result = model.evaluate(test_generator)\n",
        "print('loss for test data :', result[0])\n",
        "print('accuracy for test data :', result[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkwR7BI_Gl7n"
      },
      "source": [
        "You will probably receive a prediction accuracy upwards of 80%, which is not bad for such a simple model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTcKMmnPG2pk"
      },
      "source": [
        "Now our model is ready to make predictions! This can be done with the `model.predict` function. To predict whether a given image corresponds to a patient with or without pneumonia, we first need to download the image file and feed it into the `model.predict` function. For simplicity, we will use a file from the test data set, but we could of course also use our model for any other chest X-ray!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2_mvhL0D-1o"
      },
      "outputs": [],
      "source": [
        "!wget -O test_image_1.jpeg https://www.dropbox.com/s/z2dwy069smbrtym/test_image_1.jpeg?dl=0\n",
        "path = 'test_image_1.jpeg'  # File path to an image from the test data set\n",
        "img = tf.keras.utils.load_img(path, target_size=(300,300))   # Load image\n",
        "x = tf.keras.utils.img_to_array(img)     # Turn image into array\n",
        "x = x/255 # Scale\n",
        "x = np.expand_dims(x, axis=0)   # Add one dimension to match the input size expected by our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjoLy7T0Kx0G"
      },
      "outputs": [],
      "source": [
        "prob_pneumonia = model.predict(x)\n",
        "prob_pneumonia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KooWY7lOknuH"
      },
      "source": [
        "---\n",
        "#### **_Your turn_: Exercises**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMh_LLQ6XJEz"
      },
      "source": [
        "**Exercise 1**: The variable `prob_pneumonia` gives the probability that the image comes from a pneumonia patient. Write a few lines of code to print 'The patient has pneumonia' if this probability is greater than 50%, and 'The patient does not have pneumonia' otherwise.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikg7piuDXQSg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQ2baKahXaRR"
      },
      "source": [
        "**Exercise 2**: As (future) medical doctors, you might also want to take a look at the image yourself. You can display it using the `imshow` function of `matplotlib` as shown below. Do you agree with your model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMAQIBeGOPTk"
      },
      "outputs": [],
      "source": [
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUpkAxjrU9ec"
      },
      "source": [
        "**Exercise 3**: If you're still feeling motivated, you can repeat the evaluation for the image file called `test_image_2.jpeg` which you can download from https://www.dropbox.com/s/z471e1sbeac29g7/test_image_2.jpeg?dl=0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmsFrKYg6pqE"
      },
      "source": [
        "**Exercise 4:** If you're STILL feeling motivated and you have some time to spare this afternoon: What happens if, instead of our model with five convolutions, you use your model with only three convolutions (`model2`)? Does this affect the performance of your model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWqA8NKd7Ewp"
      },
      "source": [
        "---\n",
        "## **8. Optional: More MNIST**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qmee_y0G94m7"
      },
      "source": [
        "Here you can try out how different network architectures and training parameters affect the performance of a deep learning model for the MNIST dataset. We will start with the following architecture:\n",
        "*   input shape 28Ã28Ã1 (the size of the images),\n",
        "*   1st convolutional layer with 64 filters, kernel size (3,3), stride (1,1) and ReLu activations,\n",
        "*   dropout layer which drops 20% of the input units,\n",
        "*   2nd convolutional layer with 32 filters, kernel size (3,3), stride (1,1) and ReLu activations,\n",
        "*   flatten layer,\n",
        "*   dense output layer with 10 units and softmax activation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1-MzujF-Qfe"
      },
      "source": [
        "**Load and prepare data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vFqxc8AD94aO"
      },
      "outputs": [],
      "source": [
        "# Import the MNIST dataset\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load MNIST images and labels and normalise (range 0 to 1) image data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data() # 60,000 training + 10,000 test images/labels\n",
        "X_train = X_train / 255.0\n",
        "X_test  = X_test / 255.0\n",
        "\n",
        "# Reshape dataset to have a single channel\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)) # The CNN requires this layout (batch_size, height, width, n_channels)\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)) # The CNN requires this layout (batch_size, height, width, n_channels)\n",
        "\n",
        "# One-hot encode target values (i.e. make all the values 0 or 1)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoIimFom-gWP"
      },
      "source": [
        "**Build model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eh0Jv9Hs7EK0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(28,28,1)))\n",
        "model.add(Conv2D(64, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
        "model.add(Flatten()) # This flattens your image with width and height into a vector of length widht*height.\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z02Qnhtg-rrQ"
      },
      "source": [
        "**Compile model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G4-KlOTd6km7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "# Loss function\n",
        "loss = CategoricalCrossentropy()\n",
        "\n",
        "model.compile(loss=loss,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTIQcz6N_g8M"
      },
      "source": [
        "**Train model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kn6fA1w2_CFM"
      },
      "outputs": [],
      "source": [
        "# Define number of epochs and batch size\n",
        "epochs = 5\n",
        "batch_size = 512\n",
        "\n",
        "# Fit model\n",
        "history = model.fit(x=X_train, y=y_train,\n",
        "                    validation_split=0.1,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMvOdfh1-u0K"
      },
      "source": [
        "**Plot loss and accuracy as a function of epochs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ISmWKXVy_Kr-"
      },
      "outputs": [],
      "source": [
        "n_epochs = np.arange(0,epochs)\n",
        "\n",
        "fig, (ax1,ax2) = plt.subplots(2,1,figsize=(8,16))\n",
        "ax1.plot(n_epochs, history.history['loss'], label='training loss')\n",
        "ax1.plot(n_epochs, history.history['val_loss'], label='validation loss')\n",
        "ax1.set_ylim(-0.05,1.05)\n",
        "ax1.legend()\n",
        "\n",
        "ax2.plot(n_epochs, history.history['accuracy'], label='training accuracy')\n",
        "ax2.plot(n_epochs, history.history['val_accuracy'], label='validation accuracy')\n",
        "ax2.set_ylim(-0.05,1.05)\n",
        "ax2.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bc5WsRka_nCk"
      },
      "source": [
        "**Evaluate model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W37EqAu7_moq"
      },
      "outputs": [],
      "source": [
        "loss_and_metrics = model.evaluate(X_test, y_test,\n",
        "                                  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPwXxwv7AHhb"
      },
      "source": [
        "---\n",
        "#### **_Your turn_: Exercises**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQC6E8gTAUWh"
      },
      "source": [
        "**Exercise 1:** Try changing the architecture of your model, e.g. by adding layers or changing the type of layers. How does this affect model performance?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssZH4DbyAoMt"
      },
      "source": [
        "**Exercise 2:** Try changing the training parameters of your model, e.g. the number of epochs or the batch size. How does this affect model performance?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxF7RTDcwRgR"
      },
      "source": [
        "#**Well done!**\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "cPwXxwv7AHhb"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
